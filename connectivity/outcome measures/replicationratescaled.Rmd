---
title: "replication scaled"
author: "Victor MÃ¸ller"
date: "19 maj 2019"
output: html_document
---

```{r}

#set working directory
setwd("C:/Users/victm/Dropbox/CogSci 4/Social and Cultural Dynamics in Cognition/exam/CRUST-1/data/ABMdata/ABMcsv")

#packages
library(tidyverse)
```

Loading. 
Network = Lattice
Sample size = 100
True model = 7

```{r}

#reading 
lattice <- read.csv("lattice_csv")

#relevant subset (NB: over-writes lattice)
lattice_sub <- lattice %>%
  subset(edges_replication_study >= 1 |
         not_replicated >= 1) #the only thing relevant for replication rate.

```

lattice replication overall 

```{r}

#replication overall 
lattice_overall <- lattice %>%
  group_by(replica, network, population) %>%
  summarize(replicated = sum(replicated) / sum(not_replicated + replicated),
            not_rep = 1-replicated) 

```

lattice overall summary stats

```{r}
#summary stats
lattice_overall_sum <- lattice_overall %>%
  group_by(network, population) %>%
  summarize(median = mean(replicated),
            IQR = IQR(replicated)) 
  #mutate(final_global_true_model = "all cases")
```

lattice by global

```{r}
#replication if true & if not
lattice_byglobal <- lattice %>%
  group_by(final_global_true_model, replica, network, population) %>%
  summarize(replicated = sum(replicated) / sum(not_replicated + replicated),
            not_rep = 1-replicated) 
```

lattice summary stats by global 

```{r}
#replicated if true & if not (median & IQR)
lattice_byglobal_sum <- lattice_byglobal %>%
  group_by(final_global_true_model, network, population) %>%
  summarize(median = mean(replicated, na.rm = TRUE),
            IQR = IQR(replicated, na.rm = TRUE)) %>%
  ungroup()


#only true 
lattice_true_sum <- lattice_byglobal_sum %>%
  subset(final_global_true_model == 1) %>%
  select(network, population, median, IQR)

```

output lattice (skipped now)

```{r}
mave_all_rep <- rbind(lattice_overall_sum, lattice_byglobal_sum)
```

write.csv

```{r}
#working directory 
setwd("C:/Users/victm/Dropbox/CogSci 4/Social and Cultural Dynamics in Cognition/exam/CRUST-1/connectivity/results")

#writing csv. 
write.csv(lattice_overall_sum, file = "RR_overall_lattice.csv", row.names = F)
write.csv(lattice_true_sum, file = "RR_true_lattice.csv", row.names = F)

```


small world 

```{r}
setwd("D:/data_with_columns/formatted")

#clearing & reading 
rm(list=ls())
temp <- list.files(pattern="*.csv")

#small world 
temp <- list.files(pattern=".csv")
names(temp) <- list.files(pattern=".csv")
y <- c("small_bo_0.2_BIC_100_hard_100.csv",
       "small_bo_0.5_BIC_100_hard_100.csv", #this is fucked. 
       "small_bo_0.8_BIC_100_hard_100.csv",
       "small_epi_0.2_BIC_100_hard_100.csv",
       "small_epi_0.5_BIC_100_hard_100.csv",
       "small_epi_0.8_BIC_100_hard_100.csv",
       "small_mave_0.2_BIC_100_hard_100.csv",
       "small_mave_0.5_BIC_100_hard_100.csv",
       "small_mave_0.8_BIC_100_hard_100.csv",
       "small_tess_0.2_BIC_100_hard_100.csv",
       "small_tess_0.5_BIC_100_hard_100.csv",
       "small_tess_0.8_BIC_100_hard_100.csv")
temp <- temp[y]
temp

#loading them 
for(i in 1:length(temp)) assign(temp[i], read.csv(temp[i], sep = ","))

```

putting them together 

```{r}

#rbind them into lattice. 
small <- rbind(small_bo_0.2_BIC_100_hard_100.csv,
       small_bo_0.5_BIC_100_hard_100.csv,
       small_bo_0.8_BIC_100_hard_100.csv,
       small_epi_0.2_BIC_100_hard_100.csv,
       small_epi_0.5_BIC_100_hard_100.csv,
       small_epi_0.8_BIC_100_hard_100.csv,
       small_mave_0.2_BIC_100_hard_100.csv,
       small_mave_0.5_BIC_100_hard_100.csv,
       small_mave_0.8_BIC_100_hard_100.csv,
       small_tess_0.2_BIC_100_hard_100.csv,
       small_tess_0.5_BIC_100_hard_100.csv,
       small_tess_0.8_BIC_100_hard_100.csv)

#remove all the old shit 
rm(list=setdiff(ls(), "small"))
```

small subset 

```{r}
#relevant subset 
small_sub <- small %>%
  subset(tried >= 1) #the only thing relevant for replication rate.

```

small replication overall 

```{r}
#replication overall 
small_overall <- small_sub %>%
  group_by(replica, network, population) %>%
  summarize(replicated = sum(replicated) / sum(not_replicated + replicated),
            not_rep = 1-replicated) 
```

small summary stats overall 

```{r}
#summary stats
small_overall_sum <- small_overall %>%
  group_by(network, population) %>%
  summarize(median = mean(replicated),
            IQR = IQR(replicated)) 
  #mutate(final_global_true_model = NA)
```

small by global

```{r}
#replication if true & if not
small_byglobal <- small_sub %>%
  group_by(final_global_true_model, replica, network, population) %>% #sigma.
  summarize(replicated = sum(replicated) / sum(not_replicated + replicated),
            not_rep = 1-replicated) 
```

small summary stats by global 

```{r}
#replicated if true & if not (median & IQR)
small_byglobal_sum <- small_byglobal %>%
  group_by(final_global_true_model, network, population) %>% #sigma can be added.
  summarize(median = mean(replicated, na.rm = TRUE), #na.rm
            IQR = IQR(replicated, na.rm = TRUE)) %>%
  ungroup()#na.rm 


#only true 
small_true_sum <- small_byglobal_sum %>%
  subset(final_global_true_model == 1) %>%
  select(network, population, median, IQR)

```

small output (not used for now)

```{r}
small_all <- rbind(small_overall_sum, small_byglobal_sum)
```

small write.csv

```{r}
#working directory
setwd("C:/Users/victm/Dropbox/CogSci 4/Social and Cultural Dynamics in Cognition/exam/CRUST-1/connectivity/results")

write.csv(small_true_sum, file = "RR_true.csv", row.names = FALSE)
write.csv(small_overall_sum, file = "RR_overall.csv", row.names = FALSE)

```

