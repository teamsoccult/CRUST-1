---
title: "prep_BA_reworkLOOP"
author: "Victor MÃ¸ller"
date: "November 14, 2019"
output: html_document
---
14-09-2019
This document tests & cleans data from ABM5. 
It is probably only going to work for test-phase with small
amounts of data. It takes data from "new_data" folder and outputs to "tests".

```{r}

#packages
library(pacman)
p_load(tidyverse, tidyselect, data.table)

```

First chunk is a screening of the data. 
Does it pass our sanity checks & do we have all cases? 

```{r}

#Working directory of RAW data. 
setwd("D:/data_new1")

#for basic tests
condition <- list()
network <- list()
population <- list()
sigma <- list()
base_SS <- list()
true_model <- list()
replica <- list()

#for other tests 
studiesMAX <- list()
studiesMIN <- list()

#the masterlist
masterlist <- list()

#your files 
files = list.files(pattern=c("*.csv"), full.names=TRUE)

#running the function
datacheck <- function(i){
  
  for(i in files){
    
  #reading data
  data <- read_csv(i)
  data <- na.omit(data)
  data <- tibble::as_tibble(data)
  
  #factorizing 
  data <- data %>%
  mutate(network = factor(network),
         population = factor(population),
         sigma = factor(sigma),
         net_size = factor(net_size),
         base_SS = factor(base_SS),
         true_model = factor(true_model),
         colab_cond = factor(colab_cond),
         orig_type = factor(orig_type),
         strategy = factor(strategy))
  
  #basic tests 
  condition[i] <- paste0(i)
  network[i] <- levels(data$network)
  population[i] <- levels(data$population)
  sigma[i] <- levels(data$sigma)
  base_SS[i] <- levels(data$base_SS)
  true_model[i] <- levels(data$true_model)
  replica[i] <- sum(unique(data$replica))
  
  #more tests 1: all replicas 10,000. 
  check <- data %>%
  group_by(replica, network, population, sigma, true_model,
           base_SS, net_size, colab_cond) %>%
  summarize(stud = max(studies))
  
  studiesMAX[i] <- min(check$stud) #10,000
  studiesMIN[i] <- max(check$stud) #10,000
  
  }
  
  masterlist <- list(network, population, sigma, base_SS,
                     true_model, replica, studiesMAX, studiesMIN)
  return(masterlist)
  
}

test <- datacheck(files)

## taking out parameters 
network <- unname(unlist(test[[1]]))
population <- unname(unlist(test[[2]]))
sigma <- unname(unlist(test[[3]]))
base_SS <- unname(unlist(test[[4]]))
true_model <- unname(unlist(test[[5]]))
replica <- unname(unlist(test[[6]]))
studiesMAX <- unname(unlist(test[[7]]))
studiesMIN <- unname(unlist(test[[8]]))

#checking
network
population
sigma
base_SS
true_model
replica
studiesMAX
studiesMIN

```

write the cleaned files into another directory

```{r}

#Working directory of RAW data. 
setwd("D:/data_new1")

#your files 
files = list.files(pattern=c("*.csv"), full.names=TRUE)

#the function
datawrite <- function(i){
  
  for(i in files){
  
  #where your raw files are:   
  setwd("D:/data_new1")
    
  #reading data:
  data <- read_csv(i)
  data <- na.omit(data)
  data <- tibble::as_tibble(data)
  
  #factorizing (might not work anyways): 
  data <- data %>%
  mutate(network = factor(network),
         population = factor(population),
         sigma = factor(sigma),
         net_size = factor(net_size),
         base_SS = factor(base_SS),
         true_model = factor(true_model),
         colab_cond = factor(colab_cond),
         orig_type = factor(orig_type),
         strategy = factor(strategy))
  
  #directory for the files: 
  setwd("D:/data_prepped1")
  
  #write csv:
  write_csv(data, paste0(i))
  
  }
}

datawrite(files)


```

data preparation for "violin_extended_rework": 

```{r}

#working directory. 
setwd("D:/data_prepped1")
path = "D:/data_prepped1/"
files <- list.files(path = path, pattern="*.csv")

#initializing empty list 
datalist <- list()

violin_extended_rework <- function(files){
  
  #selecting cols (check )
    mycols <- c("replica", 
            "turn", 
            "studies", 
            "network", 
            "population", 
            "sigma",
            "base_SS",
            "colab_cond",
            "net_size",
            "true_model",
            "strategy",
            "switch_rep_study",
            "switch_rep",
            "prop_true",
            "prop_t_mod")
  
  for(i in files){

    #read csv 
    df <- read_csv(i)[mycols]
    
    #as factor
    df <- df %>%
    mutate(network = factor(network),
          population = factor(population),
          sigma = factor(sigma),
          base_SS = factor(base_SS),
          colab_cond = factor(colab_cond),
          net_size = factor(net_size),
          true_model = factor(true_model),
          strategy = factor(strategy))
    
    #create DF. 
    df <- df %>%
        group_by(replica, network, population, sigma, true_model,
           base_SS, net_size, colab_cond) %>%
        summarize(RR = sum(switch_rep) / 
              sum(switch_rep_study)) 
    
    datalist[i] <- list(df)
  }
    
  df_final <- do.call("rbind", datalist)
  
  #directory for the files: 
  setwd("D:/data_plotting")
  
  #write csv:
  write_csv(df_final, "violin_extended_rework.csv")

}

#calling the function
violin_extended_rework(files)

```

data preparation for "violin_ridges_rework":

```{r}

    #create DF.
    #working directory.
setwd("~/CRUST-1/data_prepped1")
path = "~/CRUST-1/data_prepped1/"
files <- list.files(path = path, pattern="*.csv")

#initializing empty list
datalist1 <- list()
datalist2 <- list()


violin_extended_rework <- function(files){
 
  #selecting cols (check )
    mycols <- c("replica", 
            "turn", #need this??
            "studies", 
            "network", 
            "colab_cond",
            "population", 
            "sigma",
            "net_size",
            "base_SS",
            "true_model",
            "strategy",
            "switch_rep_study",
            "switch_rep",
            "prop_true",
            "prop_t_mod") #importantly. 
 
  for(i in files){

    #read csv
    df <- read_csv(i)[mycols]
    
    #as factor
    df <- df %>%
    mutate(network = factor(network),
          population = factor(population),
          sigma = factor(sigma),
          base_SS = factor(base_SS),
          colab_cond = factor(colab_cond),
          net_size = factor(net_size),
          true_model = factor(true_model),
          strategy = factor(strategy))
    
    #replication rate & TAT overall
    RR_TAT <- df %>%
    group_by(replica, network, population, sigma, true_model,
             base_SS, net_size, colab_cond) %>%
    summarize(RR = sum(switch_rep) / sum(switch_rep_study),
              TAT = mean(prop_true)) %>%
    ungroup %>%
    mutate(base_SS = ifelse(base_SS == 20,
                                "Sample size: 20",
                                "Sample size: 100"))

    #replication rate & TAT (for )
    #legit to compute TAT for the subset?
    RR_TAT_TF <- df %>%
    group_by(prop_t_mod, replica, network, population, sigma, true_model,
             base_SS, net_size, colab_cond) %>%
    summarize(RR = sum(switch_rep) / sum(switch_rep_study),
              TAT = mean(prop_true)) %>%
    ungroup %>%
    mutate(base_SS = ifelse(base_SS == 20,
                                "Sample size: 20",
                                "Sample size: 100"))
    
    datalist1[i] <- list(RR_TAT)
    datalist2[i] <- list(RR_TAT_TF)
  }
    
  RR_TAT <- do.call("rbind", datalist1)
  RR_TAT_TF <- do.call("rbind", datalist2)
 
  #directory for the files:
  setwd("/run/media/victormp/VERBATIM HD/data_plotting")
 
  #write csv:
  write_csv(RR_TAT, "violin_ridges_RR.csv")
  write_csv(RR_TAT_TF, "violin_ridges_TF.csv")

}

#calling the function
violin_extended_rework(files)

    


```

###OUTCOME MEASURES:
____________________
Data prep for "Stickiness":

```{r}
#working directory. 
setwd("E:/data_prepped1")
path = "E:/data_prepped1/"
files <- list.files(path = path, pattern="*.csv")

#initializing empty list 
datalist <- list()

stickiness_rework <- function(files){
  
  #selecting cols (check )
    mycols <- c("replica", 
                "network", 
                "population", 
                "sigma",
                "true_model",
                "net_size", #maybe relevant.
                "colab_cond",
                "base_SS", #maybe relevant. 
                "prop_t_mod", #proposed true? (1 = yes, 0 = no). 
                "init_g_true", #count of true orig. (testing) agents.
                "final_g_true", #count of post stud. (testing) agents. 
                "switch_true",
                "switch_true_changing")
  
  for(i in files){

    #read csv 
    df <- read_csv(i)[mycols]
    
    #as factor
    df <- df %>%
    mutate(network = factor(network),
          population = factor(population),
          sigma = factor(sigma),
          base_SS = factor(base_SS),
          colab_cond = factor(colab_cond),
          net_size = factor(net_size),
          true_model = factor(true_model))
    
    #create DF
    df <- df %>%
      filter(prop_t_mod == 0) %>%
      group_by(replica, sigma, population, network, true_model,
           net_size, colab_cond, base_SS) %>%
      summarize(agent_away = sum(as.numeric(init_g_true == 1 & 
                                        final_g_true == 0)),
            agent_total = sum(as.numeric(init_g_true == 1)),
            switch_away = sum(switch_true_changing),
            switch_total = sum(switch_true))
    
    datalist[i] <- list(df)
  }
    
  df_final <- do.call("rbind", datalist)
  
  #directory for the files: 
  setwd("E:/data_outcome_measures")
  
  #write csv:
  write_csv(df_final, "stickiness_rework.csv")

}

#calling the function
stickiness_rework(files)
```

